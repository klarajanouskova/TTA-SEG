{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c93a1570",
   "metadata": {},
   "source": [
    "# Inference-time self-supervised learning demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1996adc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from inference_ssl import *\n",
    "from icon_eval import eval_preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b48325",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec3a665c",
   "metadata": {},
   "source": [
    "## Show results on Pascal VOC FG/BG segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "470fd38b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from util.icon_dataset import Transformation, Resize\n",
    "from icon_eval import ToTensorUnscaled\n",
    "\n",
    "from util.voc_dataset import VOCSegmentationSubFgBg, HBBoxTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba945267",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Prepare the data and model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9cfa9c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0006b42a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBOX GT /Users/panda/Technion/datasets/voc/VOCdevkit/VOC2012/ImageSets/Segmentation/bboxes_cat&dog.npy does not exist, it will be created now.\n",
      "BBOX GT has been created successfully!\n",
      "Namespace(model_name='unet3_bce_iou', model_pick='best', model='mae_vit_base_patch16_seg_conv_unet', unet_depth=3, data_path='/Users/panda/Technion/datasets', batch_size=4, input_size=384, num_workers=4, dataset_name='SOD', ssl_iter_num=15)\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "args = get_inference_args(notebook=True)\n",
    "args.batch_size = 4\n",
    "root = os.path.join(dataset_dir, 'voc')\n",
    "    # add some space around the objects if possible\n",
    "bbox_trans = HBBoxTransform(range=(0.3, 0.3))\n",
    "# sub = 'all'\n",
    "im_transform = tfms.Compose([Transformation(train=False, size=args.input_size)])\n",
    "mask_transform = tfms.Compose([Resize(args.input_size, args.input_size)])\n",
    "sub = 'cat&dog'\n",
    "dataset = VOCSegmentationSubFgBg(root=root,\n",
    "                                 sub=sub,\n",
    "                                 transform=im_transform,\n",
    "                                 target_transform=mask_transform,\n",
    "                                 bbox_transform=bbox_trans)\n",
    "\n",
    "print(args)\n",
    "batch_size = 1 if args.tta_iter_num > 0 else args.batch_size\n",
    "\n",
    "model = load_model(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "819cf4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_noise_fun = lambda x: (x + torch.randn_like(x) * 0.2)\n",
    "poisson_noise_fun = lambda x: (x + torch.poisson(x * 0.9) / 0.9).clamp(0, 1)\n",
    "gauss_fun = lambda x: torch.einsum('chw -> hwc', F.gaussian_blur(torch.einsum('hwc -> chw', x), kernel_size=5, sigma=3))\n",
    "contrast_fun = lambda x: torch.einsum('chw -> hwc', F.adjust_contrast(torch.einsum('hwc -> chw', x), 2))\n",
    "brightness_fun = lambda x: torch.einsum('chw -> hwc', F.adjust_brightness(torch.einsum('hwc -> chw', x), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0544cfd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Run optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebfaaab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "iter 0: mse_rec = 0.11135008931159973, mse_init_rec = 0.11135008931159973\n",
      "iter 1: mse_rec = 0.1079242080450058, mse_init_rec = 0.1079242080450058\n",
      "iter 2: mse_rec = 0.11442174017429352, mse_init_rec = 0.11442174017429352\n",
      "iter 3: mse_rec = 0.10951656103134155, mse_init_rec = 0.10951656103134155\n",
      "iter 4: mse_rec = 0.10846338421106339, mse_init_rec = 0.10846338421106339\n",
      "iter 5: mse_rec = 0.12167128920555115, mse_init_rec = 0.12167128920555115\n",
      "iter 6: mse_rec = 0.12181101739406586, mse_init_rec = 0.12181101739406586\n",
      "iter 7: mse_rec = 0.11962278932332993, mse_init_rec = 0.11962278932332993\n",
      "iter 8: mse_rec = 0.12482544034719467, mse_init_rec = 0.12482544034719467\n",
      "iter 9: mse_rec = 0.12003853917121887, mse_init_rec = 0.12003853917121887\n",
      "iter 10: mse_rec = 0.11341214179992676, mse_init_rec = 0.11341214179992676\n",
      "iter 11: mse_rec = 0.11557735502719879, mse_init_rec = 0.11557735502719879\n"
     ]
    }
   ],
   "source": [
    "idxs = [76, 77, 80, 100]\n",
    "idxs = np.arange(120, 125)\n",
    "\n",
    "for idx in idxs:\n",
    "    img, gt, clses, name = dataset[idx]\n",
    "\n",
    "    gt = (gt > 0).astype(int)\n",
    "    # reload model\n",
    "    model = load_model(args)\n",
    "    model.eval() # makes sure layers like batchnorm or dropout are in eval mode \n",
    "    model.freeze_decoder()\n",
    "    # iterative ssl optimization\n",
    "    \n",
    "    (preds_seg, preds_rec) = optimize_im(img=gauss_noise_fun(torch.tensor(img).to(device)), model=model, num_it=20, thresh=0.1,\n",
    "                                         lr=1e-2, bs=args.batch_size, mask_ratio=0.5, debug=True)\n",
    "    maes_seg, maes_rec, ious_seg = eval_preds(preds_seg, preds_rec, gt, img)\n",
    "    plot_results(name, img, gt, preds_seg, preds_rec, maes_seg, maes_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe950d80",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpred\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
