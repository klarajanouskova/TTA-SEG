program:
  main_finetune_seg.py
name:
  unet
method: grid
parameters:
  exp_name:
    values: ["log_test"]
  input_size:
    values: [384]
  lr:
    values: [5e-5]
  layer_decay:
    values: [1]
  rec_weight:
    values: [1.0]
  seg_weight:
    values: [1.]
  unet_depth:
    values: [2]
  loss:
    values: ["BCE+IoU"]
  data_cls_sub:
#    values: ["A", "B"]
    values: [ "all" ]
  epochs:
    values: [10]
  test:
    values: [0]
  batch_size:
#    values: [4]
    values: [8]
  patch_size:
    values: [16]
  freeze_encoder:
    values: [0]
  num_workers:
    values: [8]
  preserve_aspect:
    values: [1]
#    python -m torch.distributed.launch --nproc_per_node=3 main_finetune_self_base.py --world_size 3
command:
  - ${env}
  - python
  - "-m"
  - torch.distributed.launch
  - "--nproc_per_node=2"
  - "--master_port=2951"
  - ${program}
  - "--world_size=2"
  - ${args}
project:
  TTA-finetune
entity:
  klara